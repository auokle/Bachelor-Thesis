{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fbf8d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc3010f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"working_data/mhs_sleep_ch_without_outliers.csv\")\n",
    "df['LOWER_DAYS'] = pd.to_datetime(df['LOWER_DAYS'])\n",
    "df['WEEKDAY'] = df['LOWER_DAYS'].dt.day_name()\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17159613",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb92c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function to find first monday\n",
    "def filter_from_first_monday(group):\n",
    "    monday_idx = group.index[group['LOWER_DAYS'].dt.weekday == 0]\n",
    "    if monday_idx.empty:\n",
    "        return pd.DataFrame()\n",
    "    start_idx = monday_idx.min()\n",
    "    return group.loc[start_idx:]\n",
    "\n",
    "df = df.groupby('USER_ID', group_keys=False).apply(filter_from_first_monday)\n",
    "\n",
    "print(df.columns)\n",
    "\n",
    "df['WEEKDAY_STR'] = df['LOWER_DAYS'].dt.day_name().str[:3] # add weekday string to check later\n",
    "df['WEEKDAY_NUM'] = df['LOWER_DAYS'].dt.weekday # add weekday number from 0=Monday to 6=Sunday\n",
    "\n",
    "df['WEEK_START'] = df['LOWER_DAYS'] - pd.to_timedelta(df['LOWER_DAYS'].dt.weekday, unit='D')\n",
    "\n",
    "print(df.columns)\n",
    "\n",
    "# find weeks with values for every day\n",
    "def check_continuous_dates(group):\n",
    "    expected_days = set(range(7))\n",
    "    actual_days = set(group['WEEKDAY_NUM'].unique())\n",
    "\n",
    "    # drop week if day is missing\n",
    "    if actual_days != expected_days:\n",
    "        return pd.DataFrame()\n",
    "    else:\n",
    "        return group\n",
    "\n",
    "# check for continuous dates\n",
    "df = df.groupby(['USER_ID', 'WEEK_START']).apply(check_continuous_dates)\n",
    "\n",
    "print(df.columns)\n",
    "\n",
    "for i, day in enumerate(['Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun']):\n",
    "    df[f'DATE_{day}'] = df['WEEK_START'] + pd.to_timedelta(i, unit='D')\n",
    "    \n",
    "print(df.columns)\n",
    "\n",
    "id_vars = ['USER_ID', 'WEEK_START', 'WEEKDAY_STR']\n",
    "value_vars = [col for col in df.columns if col not in id_vars + ['LOWER_DAYS', 'WEEKDAY_NUM', 'DATE_Mon', 'DATE_Tue', 'DATE_Wed', 'DATE_Thu', 'DATE_Fri', 'DATE_Sat', 'DATE_Sun']]\n",
    "\n",
    "melted = df.melt(id_vars=id_vars, value_vars=value_vars, var_name='feature', value_name='value')\n",
    "\n",
    "melted['feature_day'] = melted['feature'] + '_' + melted['WEEKDAY_STR']\n",
    "\n",
    "weekly_df = melted.pivot_table(index=['USER_ID', 'WEEK_START'], columns='feature_day', values='value', aggfunc='first')\n",
    "\n",
    "weekly_df.columns.name = None\n",
    "weekly_df = weekly_df.reset_index()\n",
    "\n",
    "for i, day in enumerate(['Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun']):\n",
    "    weekly_df[f'DATE_{day}'] = pd.to_datetime(weekly_df['WEEK_START']) + pd.to_timedelta(i, unit='D')\n",
    "\n",
    "print(weekly_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d49b3e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort all parameters according to weekdays\n",
    "\n",
    "weekdays = ['Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun']\n",
    "\n",
    "weekday_columns = [col for col in weekly_df.columns if any(col.endswith(f\"_{day}\") for day in weekdays)]\n",
    "\n",
    "ordered_columns = ['USER_ID', 'WEEK_START'] + sorted(weekday_columns, key=lambda x: weekdays.index(x.split('_')[-1]))\n",
    "\n",
    "weekly_df = weekly_df[ordered_columns]\n",
    "\n",
    "print(weekly_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a359690",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "print(weekly_df.columns.tolist()[:33])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f15a173d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check whether there are still NaN values or whether they have been sorted out\n",
    "\n",
    "print(\"Number of rows:\", len(weekly_df))\n",
    "print(\"Number of rows with NaN values:\", weekly_df.isna().any(axis=1).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc2258e",
   "metadata": {},
   "outputs": [],
   "source": [
    "weekly_df.to_csv(\"working_data/mhs_sleep_weekly.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
