{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db0d090",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import umap.umap_ as umap\n",
    "import seaborn as sns\n",
    "import matplotlib.colors as mcolors\n",
    "import numpy as np\n",
    "from sklearn.feature_selection import VarianceThreshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "560ba254",
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlation threshold to set\n",
    "\n",
    "threshold = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b5ae3cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter features for high correlation and low variance\n",
    "def process_dataframe(df_input, group_name, threshold=0.8, variance_threshold=0.01):\n",
    "    # drop non-feature columns\n",
    "    correlation_df = df_input.drop(columns=['USER_ID', 'WEEK_START'], errors='ignore')\n",
    "\n",
    "    # correlation matrix\n",
    "    corr_matrix = correlation_df.corr().abs()\n",
    "\n",
    "    # heatmap\n",
    "    plt.figure(figsize=(18, 14))\n",
    "    sns.heatmap(corr_matrix, cmap='coolwarm', center=0, square=True, linewidths=0.5)\n",
    "    plt.title(f'Correlation Heatmap of Weekly Variances ({group_name})')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"clustering_plots/correlation_matrix_with_variance_threshold_{threshold}_{group_name}.png\", dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "    # upper triangle matrix\n",
    "    upper_triangle_mask = np.triu(np.ones(corr_matrix.shape), k=1).astype(bool)\n",
    "    upper_triangle = corr_matrix.where(upper_triangle_mask)\n",
    "\n",
    "    # highly correlated pairs\n",
    "    high_corr_pairs = (\n",
    "        upper_triangle.stack()\n",
    "        .reset_index()\n",
    "        .rename(columns={'level_0': 'Feature 1', 'level_1': 'Feature 2', 0: 'Correlation'})\n",
    "        .query(f\"Correlation >= {threshold}\")\n",
    "        .sort_values(by=\"Correlation\", ascending=False)\n",
    "    )\n",
    "\n",
    "    print(f\"High correlation pairs for {group_name}:\")\n",
    "    print(high_corr_pairs)\n",
    "\n",
    "    # drop one variable of each correlated pair\n",
    "    to_drop = set()\n",
    "    for col in upper_triangle.columns:\n",
    "        # skip if this column is already marked for removal\n",
    "        if col in to_drop:\n",
    "            continue\n",
    "        # find partners that are highly correlated with col\n",
    "        partners = upper_triangle.index[upper_triangle[col] >= threshold]\n",
    "        to_drop.update(partners)\n",
    "\n",
    "    df_reduced = df_input.drop(columns=to_drop, errors='ignore')\n",
    "\n",
    "    # variance threshold\n",
    "    exclude_cols = ['USER_ID', 'WEEK_START']\n",
    "    df_filtered = df_reduced.drop(columns=exclude_cols, errors='ignore')\n",
    "\n",
    "    selector = VarianceThreshold(threshold=variance_threshold)\n",
    "    selector.fit(df_filtered)\n",
    "\n",
    "    feature_mask = selector.get_support()\n",
    "    low_variance_features = df_filtered.columns[~selector.get_support()]\n",
    "\n",
    "    print(f\"Low variance features for {group_name}:\")\n",
    "    print(low_variance_features.tolist())\n",
    "\n",
    "    # drop low variance features\n",
    "    df_reduced = df_reduced.drop(columns=low_variance_features, errors='ignore')\n",
    "\n",
    "    print(f\"Final number of features for {group_name}: {len(df_reduced.columns)}\")\n",
    "\n",
    "    return df_reduced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fabb6fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"working_data/mhs_sleep_weekly_features.csv\")\n",
    "print(len(df.columns))\n",
    "df_gender = pd.read_csv(\"working_data/demographics_with_age.csv\", usecols=['USER_ID', 'GENDER'])\n",
    "df_gender = pd.merge(df, df_gender, on='USER_ID', how='inner')\n",
    "\n",
    "df_m = df_gender[df_gender['GENDER'] == 'male']\n",
    "df_f = df_gender[df_gender['GENDER'] == 'female']\n",
    "\n",
    "df_m = df_m.drop(columns=['GENDER'])\n",
    "df_f = df_f.drop(columns=['GENDER'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea40bf3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_processed = process_dataframe(df, \"all\", threshold)\n",
    "#df_male_processed = process_dataframe(df_m, \"male\", threshold)\n",
    "#df_female_processed = process_dataframe(df_f, \"female\", threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d817a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute sum of survey questions\n",
    "def add_total_score(df):\n",
    "    # columns to exclude from the sum\n",
    "    non_questions = {\n",
    "        'USER_ID', 'WEEK_START', 'SURVEY_WEEK'\n",
    "    }\n",
    "    # all other columns are survey questions\n",
    "    question_cols = [c for c in df.columns if c not in non_questions]\n",
    "    # row-wise sum\n",
    "    df = df.copy()\n",
    "    df['total_score'] = df[question_cols].sum(axis=1)\n",
    "    return df\n",
    "\n",
    "def filter_survey_weeks(df_survey_subset, df_features, n_weeks):\n",
    "    df_survey_subset = df_survey_subset.copy()\n",
    "    df_survey_subset['WEEK_START'] = pd.to_datetime(df_survey_subset['WEEK_START'])\n",
    "    df_features['WEEK_START'] = pd.to_datetime(df_features['WEEK_START'])\n",
    "\n",
    "    df_features = df_features.rename(columns={'WEEK_START': 'FEATURE_WEEK'})\n",
    "    df_survey_subset = df_survey_subset.rename(columns={'WEEK_START': 'SURVEY_WEEK'})\n",
    "\n",
    "    # merge on USER_ID to pair survey weeks with cluster weeks\n",
    "    df_merged = df_features.merge(df_survey_subset, on='USER_ID', how='inner')\n",
    "\n",
    "    # filter for same or up to n_weeks weeks before the cluster week\n",
    "    df_filtered = df_merged[\n",
    "        (df_merged['SURVEY_WEEK'] <= df_merged['FEATURE_WEEK']) &\n",
    "        (df_merged['SURVEY_WEEK'] >= (df_merged['FEATURE_WEEK'] - pd.Timedelta(weeks=n_weeks)))\n",
    "    ]\n",
    "\n",
    "    df_filtered = df_filtered.rename(columns={'FEATURE_WEEK': 'WEEK_START'})\n",
    "    return df_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c891a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "stress = [\n",
    "    'HOW OFTEN HAVE YOU BEEN UPSET BECAUSE OF SOMETHING THAT HAPPENED UNEXPECTEDLY?',\n",
    "    'HOW OFTEN HAVE YOU FELT THAT YOU WERE UNABLE TO CONTROL THE IMPORTANT THINGS IN YOUR LIFE?',\n",
    "    'HOW OFTEN HAVE YOU FELT NERVOUS AND STRESSED?',\n",
    "    'HOW OFTEN HAVE YOU FELT CONFIDENT ABOUT YOUR ABILITY TO HANDLE YOUR PERSONAL PROBLEMS?',\n",
    "    'HOW OFTEN HAVE YOU FELT THAT THINGS WERE GOING YOUR WAY?',\n",
    "    'HOW OFTEN HAVE YOU FOUND THAT YOU COULD NOT COPE WITH ALL THE THINGS THAT YOU HAD TO DO?',\n",
    "    'HOW OFTEN HAVE YOU BEEN ABLE TO CONTROL IRRITATIONS IN YOUR LIFE?',\n",
    "    'HOW OFTEN HAVE YOU FELT THAT YOU WERE ON TOP OF THINGS?',\n",
    "    'HOW OFTEN HAVE YOU BEEN ANGERED BECAUSE OF THINGS THAT WERE OUTSIDE OF YOUR CONTROL?',\n",
    "    'HOW OFTEN HAVE YOU FELT DIFFICULTIES WERE PILING UP SO HIGH THAT YOU COULD NOT OVERCOME THEM?'\n",
    "]\n",
    "\n",
    "depression = [\n",
    "    'HOW OFTEN HAVE YOU HAD LITTLE INTEREST OR PLEASURE IN DOING THINGS?',\n",
    "    'HOW OFTEN HAVE YOU FELT DOWN, DEPRESSED OR HOPELESS?',\n",
    "    'HOW OFTEN HAVE YOU FELT NERVOUS, ANXIOUS OR ON EDGE?',\n",
    "    'HOW OFTEN HAVE YOU NOT BEEN ABLE TO STOP OR CONTROL WORRYING?'    \n",
    "]\n",
    "\n",
    "needs = [\n",
    "    'I FELT A SENSE OF CONTACT WITH PEOPLE WHO CARE FOR ME, AND WHOM I CARE FOR',\n",
    "    'I FELT CLOSE AND CONNECTED WITH OTHER PEOPLE WHO ARE IMPORTANT TO ME',\n",
    "    'I FELT A STRONG SENSE OF INTIMACY WITH THE PEOPLE I SPENT TIME WITH',\n",
    "    'I FELT THAT I WAS SUCCESSFULLY COMPLETING DIFFICULT TASKS AND PROJECTS',\n",
    "    'I FELT THAT I WAS TAKING ON AND MASTERING HARD CHALLENGES',\n",
    "    'I FELT VERY CAPABLE IN WHAT I DID',\n",
    "    'I FELT THAT MY CHOICES WERE BASED ON MY TRUE INTERESTS AND VALUES',\n",
    "    'I FELT FREE TO DO THINGS MY OWN WAY',\n",
    "    'I FELT MY CHOICES EXPRESSED MY “TRUE SELF”'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae3b5e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create total score of survey by category\n",
    "\n",
    "df_survey = pd.read_csv(\"working_data/mhs_survey_sorted_without_nan.csv\")\n",
    "\n",
    "df_survey['SUBMITDATE'] = pd.to_datetime(df_survey['SUBMITDATE'])\n",
    "df_survey['WEEK_START'] = df_survey['SUBMITDATE'] - pd.to_timedelta(df_survey['SUBMITDATE'].dt.weekday, unit='D')\n",
    "df_survey.drop(columns=[\"SUBMITDATE\"], inplace=True)\n",
    "\n",
    "# stress\n",
    "columns_to_keep = ['USER_ID', 'WEEK_START'] + stress\n",
    "df_survey_stress = df_survey[columns_to_keep].copy()\n",
    "\n",
    "df_stress = add_total_score(df_survey_stress)\n",
    "df_stress = df_stress[['USER_ID', 'WEEK_START', 'total_score']]\n",
    "\n",
    "df_stress = filter_survey_weeks(df_stress, df_all_processed, 3)\n",
    "df_stress = df_stress.sort_values(by=['USER_ID', 'SURVEY_WEEK'], ascending=[True, False])\n",
    "df_stress.drop(columns=[\"SURVEY_WEEK\"], inplace=True)\n",
    "print(f\"Number of entries in stress: {len(df_stress)}\")\n",
    "\n",
    "# depression\n",
    "columns_to_keep = ['USER_ID', 'WEEK_START'] + depression\n",
    "df_survey_depression = df_survey[columns_to_keep].copy()\n",
    "\n",
    "df_depression = add_total_score(df_survey_depression)\n",
    "df_depression = df_depression[['USER_ID', 'WEEK_START', 'total_score']]\n",
    "\n",
    "df_depression = filter_survey_weeks(df_depression, df_all_processed, 1)\n",
    "df_depression = df_depression.sort_values(by=['USER_ID', 'SURVEY_WEEK'], ascending=[True, False])\n",
    "df_depression.drop(columns=[\"SURVEY_WEEK\"], inplace=True)\n",
    "print(f\"Number of entries in depression: {len(df_depression)}\")\n",
    "\n",
    "# needs\n",
    "columns_to_keep = ['USER_ID', 'WEEK_START'] + needs\n",
    "df_survey_needs = df_survey[columns_to_keep].copy()\n",
    "\n",
    "df_needs = add_total_score(df_survey_needs)\n",
    "df_needs = df_needs[['USER_ID', 'WEEK_START', 'total_score']]\n",
    "\n",
    "df_needs = filter_survey_weeks(df_needs, df_all_processed, 0)\n",
    "df_needs = df_needs.sort_values(by=['USER_ID', 'SURVEY_WEEK'], ascending=[True, False])\n",
    "df_needs.drop(columns=[\"SURVEY_WEEK\"], inplace=True)\n",
    "print(f\"Number of entries in needs: {len(df_needs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf5b24f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_features_by_survey_correlation(df, threshold=0.1):\n",
    "\n",
    "    id_cols = ['USER_ID', 'WEEK_START']\n",
    "    # all other columns except the total score are treated as features\n",
    "    feat_cols = [c for c in df.columns if c not in id_cols + ['total_score']]\n",
    "    \n",
    "    # compute Pearson r for each feature vs. total_score\n",
    "    corrs = df[feat_cols].corrwith(df['total_score'])\n",
    "    \n",
    "    print(\"Correlation with total_score for each feature:\")\n",
    "    for feature, r in corrs.abs().sort_values(ascending=False).items():\n",
    "        print(f\"{feature:<40}: {r:.3f}\")\n",
    "    \n",
    "    # select those with abs(r) > threshold\n",
    "    kept = corrs.abs()[corrs.abs() > threshold].index.tolist()\n",
    "    \n",
    "    return df[id_cols + kept]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a16c1e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stress\n",
    "# create dataframe with survey data\n",
    "survey_threshold = 0.05\n",
    "\n",
    "df_selected = filter_features_by_survey_correlation(df_stress, threshold=survey_threshold)\n",
    "\n",
    "# keep selected columns in features dataset\n",
    "selected_cols = df_selected.columns.tolist()\n",
    "df_all_filtered = df_all_processed[selected_cols].copy()\n",
    "print(len(df_all_filtered.columns), \"columns kept:\")\n",
    "print(df_all_filtered.columns.tolist())\n",
    "\n",
    "print(len(df_all_filtered)-2)\n",
    "\n",
    "group_name = \"all\"\n",
    "\n",
    "df_all_filtered.to_csv(f\"working_data/mhs_sleep_weekly_uncorr_features_correlation_threshold_{threshold}_{group_name}_stress.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6407b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# depression\n",
    "# create dataframe with survey data\n",
    "survey_threshold = 0.05\n",
    "\n",
    "df_selected = filter_features_by_survey_correlation(df_depression, threshold=survey_threshold)\n",
    "\n",
    "# keep selected columns in features dataset\n",
    "selected_cols = df_selected.columns.tolist()\n",
    "df_all_filtered = df_all_processed[selected_cols].copy()\n",
    "print(len(df_all_filtered.columns), \"columns kept:\")\n",
    "print(df_all_filtered.columns.tolist())\n",
    "\n",
    "print(len(df_all_filtered)-2)\n",
    "\n",
    "group_name = \"all\"\n",
    "\n",
    "df_all_filtered.to_csv(f\"working_data/mhs_sleep_weekly_uncorr_features_correlation_threshold_{threshold}_{group_name}_depression.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb028b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# needs\n",
    "# create dataframe with survey data\n",
    "survey_threshold = 0.05\n",
    "\n",
    "df_selected = filter_features_by_survey_correlation(df_needs, threshold=survey_threshold)\n",
    "\n",
    "# keep selected columns in features dataset\n",
    "selected_cols = df_selected.columns.tolist()\n",
    "df_all_filtered = df_all_processed[selected_cols].copy()\n",
    "print(len(df_all_filtered.columns), \"columns kept:\")\n",
    "print(df_all_filtered.columns.tolist())\n",
    "\n",
    "print(len(df_all_filtered)-2)\n",
    "\n",
    "group_name = \"all\"\n",
    "\n",
    "df_all_filtered.to_csv(f\"working_data/mhs_sleep_weekly_uncorr_features_correlation_threshold_{threshold}_{group_name}_needs.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
