{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f0aed21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.metrics import silhouette_score, adjusted_rand_score\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import kneighbors_graph\n",
    "from datetime import datetime\n",
    "import matplotlib.patches as mpatches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104aee5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters to set\n",
    "\n",
    "correlation_threshold = 0.8 # set this\n",
    "dim_red_method = \"umap\" # out of {\"umap\", \"pca\", \"tsne\"}\n",
    "perplexity = 50 # only used in tsne\n",
    "standardization = True\n",
    "group = \"all\" # out of {\"male\", \"female\", \"all\"}\n",
    "survey_category = \"stress\" # out of {\"stress\", \"depression\", \"needs\"}\n",
    "seed = 1 # for reproducability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "140569cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_red_method_upper = dim_red_method.upper()\n",
    "if (dim_red_method == \"tsne\"):\n",
    "    if (standardization):\n",
    "        df = pd.read_csv(f\"working_data/{dim_red_method}_features_correlation_threshold_{correlation_threshold}_perplexity_{perplexity}_with_standardization_{group}_{survey_category}.csv\")\n",
    "    else:\n",
    "        df = pd.read_csv(f\"working_data/{dim_red_method}_features_correlation_threshold_{correlation_threshold}_perplexity_{perplexity}_without_standardization_{group}_{survey_category}.csv\")\n",
    "else:\n",
    "    if (standardization):\n",
    "        df = pd.read_csv(f\"working_data/{dim_red_method}_features_correlation_threshold_{correlation_threshold}_with_standardization_{group}_{survey_category}.csv\")\n",
    "    else:\n",
    "        df = pd.read_csv(f\"working_data/{dim_red_method}_features_correlation_threshold_{correlation_threshold}_without_standardization_{group}_{survey_category}.csv\")\n",
    "X = df.iloc[:, 2:].to_numpy()\n",
    "ids = df.iloc[:, :2] # USER_ID and WEEK_START as identifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc33482a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross-validation to find most suitable number of clusters\n",
    "\n",
    "X_trainval, X_test = train_test_split(X, test_size=0.20, random_state=seed)\n",
    "\n",
    "scaler = StandardScaler().fit(X_trainval)\n",
    "X_trainval_sc = scaler.transform(X_trainval)\n",
    "X_test_sc = scaler.transform(X_test)\n",
    "\n",
    "components_range = range(2, 11)\n",
    "mean_silhouettes, mean_aris = [], []\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "base_graph = kneighbors_graph(X_trainval_sc, n_neighbors=90, include_self=False, metric='euclidean')\n",
    "\n",
    "for n in components_range:\n",
    "    # reference model on full train+val\n",
    "    hac_ref  = AgglomerativeClustering(n_clusters=n, linkage='ward',\n",
    "                                       connectivity=base_graph).fit(X_trainval_sc)\n",
    "    lbl_ref_all = hac_ref.labels_\n",
    "\n",
    "    fold_sil, fold_ari = [], []\n",
    "    for tr_idx, val_idx in kf.split(X_trainval_sc):\n",
    "        X_tr, X_val = X_trainval_sc[tr_idx], X_trainval_sc[val_idx]\n",
    "\n",
    "        # sparse graph restricted to training fold\n",
    "        cv_graph = kneighbors_graph(X_tr, n_neighbors=30, include_self=False, metric='euclidean')\n",
    "        \n",
    "        hac_cv = AgglomerativeClustering(n_clusters=n, linkage='ward', connectivity=cv_graph).fit(X_tr)\n",
    "\n",
    "        lbl_tr_cv  = hac_cv.labels_\n",
    "        lbl_tr_ref = lbl_ref_all[tr_idx]\n",
    "\n",
    "        fold_sil.append(silhouette_score(X_tr, lbl_tr_cv))\n",
    "\n",
    "        fold_ari.append(adjusted_rand_score(lbl_tr_ref, lbl_tr_cv))\n",
    "\n",
    "    mean_silhouettes.append(np.mean(fold_sil))\n",
    "    mean_aris.append(np.mean(fold_ari))\n",
    "\n",
    "    print(f\"n={n:2d} | Silhouette={mean_silhouettes[-1]:.3f} | ARI={mean_aris[-1]:.3f}\")\n",
    "\n",
    "best_n = components_range[np.argmax(mean_silhouettes)]\n",
    "print(f\"Chosen n_clusters (by CV silhouette): {best_n}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c526d61",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Silhouette\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.plot(components_range, mean_silhouettes, label='CV Silhouette', marker='o', color='tab:red')\n",
    "plt.axvline(best_n, ls='--', c='gray')\n",
    "plt.xlabel('Number of Clusters')\n",
    "plt.ylabel('Silhouette Score')\n",
    "#plt.title(f'HAC CV Silhouette vs. #Clusters ({dim_red_method_upper}, {group}, {survey_category})')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "\n",
    "if dim_red_method == \"tsne\":\n",
    "    plt.savefig(f'clustering_plots/silhouette_HAC_on_{dim_red_method_upper}_correlation_{correlation_threshold}_perplexity_{perplexity}_{group}_{survey_category}.png',\n",
    "                dpi=300, bbox_inches='tight', pad_inches=0.1, facecolor='white')\n",
    "else:\n",
    "    plt.savefig(f'clustering_plots/silhouette_HAC_on_{dim_red_method_upper}_correlation_{correlation_threshold}_{group}_{survey_category}.png',\n",
    "                dpi=300, bbox_inches='tight', pad_inches=0.1, facecolor='white')\n",
    "    \n",
    "plt.show()\n",
    "\n",
    "# ARI\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.plot(components_range, mean_aris, label='CV ARI', marker='v', color='tab:green')\n",
    "plt.axvline(best_n, ls='--', c='gray')\n",
    "plt.xlabel('Number of Clusters')\n",
    "plt.ylabel('Adjusted Rand Index')\n",
    "#plt.title(f'HAC CV ARI vs. #Clusters ({dim_red_method_upper}, {group}, {survey_category})')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "\n",
    "if dim_red_method == \"tsne\":\n",
    "    plt.savefig(f'clustering_plots/ari_HAC_on_{dim_red_method_upper}_correlation_{correlation_threshold}_perplexity_{perplexity}_{group}_{survey_category}.png',\n",
    "                dpi=300, bbox_inches='tight', pad_inches=0.1, facecolor='white')\n",
    "else:\n",
    "    plt.savefig(f'clustering_plots/ari_HAC_on_{dim_red_method_upper}_correlation_{correlation_threshold}_{group}_{survey_category}.png',\n",
    "                dpi=300, bbox_inches='tight', pad_inches=0.1, facecolor='white')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a2e987c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation on test set\n",
    "\n",
    "best_n_components = best_n\n",
    "#best_n_components = 3\n",
    "\n",
    "final_graph = kneighbors_graph(X_trainval_sc, n_neighbors=90, include_self=False, metric='euclidean')\n",
    "final_hac = AgglomerativeClustering(n_clusters=best_n_components, linkage='ward', connectivity=final_graph).fit(X_trainval_sc)\n",
    "\n",
    "# connectivity for test set\n",
    "test_graph = kneighbors_graph(X_test_sc, n_neighbors=90, include_self=False, metric='euclidean')\n",
    "test_hac = AgglomerativeClustering(n_clusters=best_n_components, linkage='ward',connectivity=test_graph).fit(X_test_sc)\n",
    "\n",
    "labels_test = test_hac.labels_ + 1\n",
    "test_silhouette = silhouette_score(X_test_sc, labels_test)\n",
    "\n",
    "print(f\"Best n_clusters: {best_n_components}\")\n",
    "print(f\"Silhouette score on test set: {test_silhouette:.3f}\")\n",
    "\n",
    "scatter = plt.scatter(X_test_sc[:, 0], X_test_sc[:, 1], c=labels_test, cmap='turbo', s=1, alpha=0.2)\n",
    "plt.xlabel(f\"{dim_red_method_upper} Component 1\")\n",
    "plt.ylabel(f\"{dim_red_method_upper} Component 2\")\n",
    "#plt.title(f'HAC with {best_n_components} clusters on {dim_red_method_upper} ({group}, {survey_category})')\n",
    "\n",
    "unique_labels = np.unique(labels_test)\n",
    "colors = [scatter.cmap(scatter.norm(label)) for label in unique_labels]\n",
    "legend_patches = [mpatches.Patch(color=color, label=f\"Cluster {label}\") for label, color in zip(unique_labels, colors)]\n",
    "plt.legend(handles=legend_patches)\n",
    "\n",
    "if dim_red_method == \"tsne\":\n",
    "    plt.savefig(f'clustering_plots/HAC_with_{best_n_components}_clusters_on_{dim_red_method_upper}_with_correlation_threshold_{correlation_threshold}_and_perplexity_{perplexity}_{group}_{survey_category}.png', \n",
    "                dpi=300, bbox_inches='tight', pad_inches=0.1, facecolor='white')\n",
    "else:\n",
    "    plt.savefig(f'clustering_plots/HAC_with_{best_n_components}_clusters_on_{dim_red_method_upper}_with_correlation_threshold_{correlation_threshold}_{group}_{survey_category}.png', \n",
    "                dpi=300, bbox_inches='tight', pad_inches=0.1, facecolor='white')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f306bd82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute HAC labels on all data\n",
    "labels_all = AgglomerativeClustering(\n",
    "    n_clusters=best_n_components,\n",
    "    linkage='ward',\n",
    "    connectivity=kneighbors_graph(scaler.transform(X), n_neighbors=90, include_self=False)\n",
    ").fit_predict(scaler.transform(X)) + 1\n",
    "\n",
    "hac_labels_df = df.iloc[:, :2].copy()  # USER_ID and WEEK_START\n",
    "hac_labels_df[f\"{dim_red_method_upper}_1\"] = X[:, 0]\n",
    "hac_labels_df[f\"{dim_red_method_upper}_2\"] = X[:, 1]\n",
    "hac_labels_df[\"cluster_label\"] = labels_all\n",
    "\n",
    "if dim_red_method == \"tsne\":\n",
    "    label_path = (\n",
    "        f\"working_data/cluster_labels/HAC_labels_{best_n_components}_clusters_on_\"\n",
    "        f\"{dim_red_method_upper}_correlation_threshold_{correlation_threshold}\"\n",
    "        f\"_perplexity_{perplexity}_{group}_{survey_category}.csv\"\n",
    "    )\n",
    "else:\n",
    "    label_path = (\n",
    "        f\"working_data/cluster_labels/HAC_labels_{best_n_components}_clusters_on_\"\n",
    "        f\"{dim_red_method_upper}_correlation_threshold_{correlation_threshold}\"\n",
    "        f\"_{group}_{survey_category}.csv\"\n",
    "    )\n",
    "\n",
    "hac_labels_df.to_csv(label_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
