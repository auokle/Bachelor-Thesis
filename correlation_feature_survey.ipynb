{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc8f02ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.multitest import multipletests\n",
    "import statsmodels.formula.api as smf\n",
    "import statsmodels.api as sm\n",
    "from scipy.stats import kruskal, chi2_contingency, pearsonr\n",
    "\n",
    "from scipy.stats import shapiro, levene, probplot, wilcoxon\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e2736d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "clustering_method = \"HAC\" # out of {\"GMM\", \"HAC\"}\n",
    "correlation_threshold = 0.8\n",
    "dim_red_method = \"umap\" # out of {\"umap\", \"pca\", \"tsne\"}\n",
    "dim_red_method_upper = dim_red_method.upper()\n",
    "perplexity = 50 # t-SNE only\n",
    "group = \"all\" # \"male\", \"female\", \"all\"\n",
    "best_n_components = 3 # found in GMM and HAC clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e06afd97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load clustering data with cluster labels for each category as well as demographic and survey data\n",
    "if dim_red_method == \"tsne\":\n",
    "    label_path = (\n",
    "        f\"working_data/cluster_labels/\"\n",
    "        f\"{clustering_method}_labels_{best_n_components}_clusters_on_\"\n",
    "        f\"{dim_red_method_upper}_correlation_threshold_{correlation_threshold}\"\n",
    "        f\"_perplexity_{perplexity}_{group}_\"\n",
    "    )\n",
    "else:\n",
    "    label_path = (\n",
    "        f\"working_data/cluster_labels/\"\n",
    "        f\"{clustering_method}_labels_{best_n_components}_clusters_on_\"\n",
    "        f\"{dim_red_method_upper}_correlation_threshold_{correlation_threshold}\"\n",
    "        f\"_{group}_\"\n",
    "    )\n",
    "\n",
    "df_clusters_stress = pd.read_csv(label_path + \"stress.csv\")\n",
    "df_clusters_depression = pd.read_csv(label_path + \"depression.csv\")\n",
    "df_clusters_needs = pd.read_csv(label_path + \"needs.csv\")\n",
    "\n",
    "df_clusters_stress['WEEK_START'] = pd.to_datetime(df_clusters_stress['WEEK_START'])\n",
    "df_clusters_depression['WEEK_START'] = pd.to_datetime(df_clusters_depression['WEEK_START'])\n",
    "df_clusters_needs['WEEK_START'] = pd.to_datetime(df_clusters_needs['WEEK_START'])\n",
    "\n",
    "# load survey data\n",
    "df_survey = pd.read_csv(\"working_data/mhs_survey_sorted_without_nan.csv\")\n",
    "\n",
    "df_survey['SUBMITDATE'] = pd.to_datetime(df_survey['SUBMITDATE'])\n",
    "df_survey['WEEK_START'] = (df_survey['SUBMITDATE'] - pd.to_timedelta(df_survey['SUBMITDATE'].dt.weekday, unit='D'))\n",
    "df_survey.drop(columns=['SUBMITDATE'], inplace=True)\n",
    "\n",
    "# load demographics data and calculate age\n",
    "df_demographics = pd.read_csv(\"original_data/mhs_demographics_sorted.csv\")\n",
    "\n",
    "df_demographics[\"FIRST_SUBMISSION_DATE\"] = pd.to_datetime(df_demographics[\"FIRST_SUBMISSION_DATE\"])\n",
    "df_demographics[\"LAST_SUBMISSION_DATE\"] = pd.to_datetime(df_demographics[\"LAST_SUBMISSION_DATE\"])\n",
    "df_demographics[\"BIRTHDAY\"] = pd.to_datetime(df_demographics[\"BIRTHDAY\"])\n",
    "\n",
    "df_demographics[\"MIDPOINT_DATE\"] = df_demographics[\"FIRST_SUBMISSION_DATE\"] + (df_demographics[\"LAST_SUBMISSION_DATE\"] - df_demographics[\"FIRST_SUBMISSION_DATE\"]) / 2\n",
    "df_demographics[\"MIDPOINT_DATE\"] = pd.to_datetime(df_demographics[\"MIDPOINT_DATE\"])\n",
    "df_demographics[\"AGE\"] = df_demographics.apply(lambda row: row[\"MIDPOINT_DATE\"].year - row[\"BIRTHDAY\"].year - ((row[\"MIDPOINT_DATE\"].month, row[\"MIDPOINT_DATE\"].day) < (row[\"BIRTHDAY\"].month, row[\"BIRTHDAY\"].day)), axis=1)\n",
    "df_demographics.rename(columns={\"WHOOP_BMI\": \"BMI\"}, inplace=True)\n",
    "df_demographics = df_demographics[[\"USER_ID\", \"AGE\", \"GENDER\", \"BMI\"]].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40620835",
   "metadata": {},
   "outputs": [],
   "source": [
    "stress = [\n",
    "    'HOW OFTEN HAVE YOU BEEN UPSET BECAUSE OF SOMETHING THAT HAPPENED UNEXPECTEDLY?',\n",
    "    'HOW OFTEN HAVE YOU FELT THAT YOU WERE UNABLE TO CONTROL THE IMPORTANT THINGS IN YOUR LIFE?',\n",
    "    'HOW OFTEN HAVE YOU FELT NERVOUS AND STRESSED?',\n",
    "    'HOW OFTEN HAVE YOU FELT CONFIDENT ABOUT YOUR ABILITY TO HANDLE YOUR PERSONAL PROBLEMS?',\n",
    "    'HOW OFTEN HAVE YOU FELT THAT THINGS WERE GOING YOUR WAY?',\n",
    "    'HOW OFTEN HAVE YOU FOUND THAT YOU COULD NOT COPE WITH ALL THE THINGS THAT YOU HAD TO DO?',\n",
    "    'HOW OFTEN HAVE YOU BEEN ABLE TO CONTROL IRRITATIONS IN YOUR LIFE?',\n",
    "    'HOW OFTEN HAVE YOU FELT THAT YOU WERE ON TOP OF THINGS?',\n",
    "    'HOW OFTEN HAVE YOU BEEN ANGERED BECAUSE OF THINGS THAT WERE OUTSIDE OF YOUR CONTROL?',\n",
    "    'HOW OFTEN HAVE YOU FELT DIFFICULTIES WERE PILING UP SO HIGH THAT YOU COULD NOT OVERCOME THEM?'\n",
    "]\n",
    "\n",
    "depression = [\n",
    "    'HOW OFTEN HAVE YOU HAD LITTLE INTEREST OR PLEASURE IN DOING THINGS?',\n",
    "    'HOW OFTEN HAVE YOU FELT DOWN, DEPRESSED OR HOPELESS?',\n",
    "    'HOW OFTEN HAVE YOU FELT NERVOUS, ANXIOUS OR ON EDGE?',\n",
    "    'HOW OFTEN HAVE YOU NOT BEEN ABLE TO STOP OR CONTROL WORRYING?'    \n",
    "]\n",
    "\n",
    "needs = [\n",
    "    'I FELT A SENSE OF CONTACT WITH PEOPLE WHO CARE FOR ME, AND WHOM I CARE FOR',\n",
    "    'I FELT CLOSE AND CONNECTED WITH OTHER PEOPLE WHO ARE IMPORTANT TO ME',\n",
    "    'I FELT A STRONG SENSE OF INTIMACY WITH THE PEOPLE I SPENT TIME WITH',\n",
    "    'I FELT THAT I WAS SUCCESSFULLY COMPLETING DIFFICULT TASKS AND PROJECTS',\n",
    "    'I FELT THAT I WAS TAKING ON AND MASTERING HARD CHALLENGES',\n",
    "    'I FELT VERY CAPABLE IN WHAT I DID',\n",
    "    'I FELT THAT MY CHOICES WERE BASED ON MY TRUE INTERESTS AND VALUES',\n",
    "    'I FELT FREE TO DO THINGS MY OWN WAY',\n",
    "    'I FELT MY CHOICES EXPRESSED MY “TRUE SELF”'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d9077b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build data frames for each survey category\n",
    "\n",
    "columns_to_keep = ['USER_ID', 'WEEK_START'] + stress\n",
    "df_survey_stress = df_survey[columns_to_keep].copy()\n",
    "\n",
    "columns_to_keep = ['USER_ID', 'WEEK_START'] + depression\n",
    "df_survey_depression = df_survey[columns_to_keep].copy()\n",
    "\n",
    "columns_to_keep = ['USER_ID', 'WEEK_START'] + needs\n",
    "df_survey_needs = df_survey[columns_to_keep].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d9ada5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to merge survey and cluster subsets and add number of weeks to include before survey week\n",
    "\n",
    "def filter_survey_weeks(df_survey_subset, df_clusters_subset, n_weeks):\n",
    "    df_survey_subset = df_survey_subset.copy()\n",
    "    df_survey_subset['WEEK_START'] = pd.to_datetime(df_survey_subset['WEEK_START'])\n",
    "\n",
    "    df_clusters_subset = df_clusters_subset.rename(columns={'WEEK_START': 'CLUSTER_WEEK'})\n",
    "    df_survey_subset = df_survey_subset.rename(columns={'WEEK_START': 'SURVEY_WEEK'})\n",
    "\n",
    "    # merge on USER_ID to pair survey weeks with cluster weeks\n",
    "    df_merged = df_clusters_subset.merge(df_survey_subset, on='USER_ID', how='inner')\n",
    "\n",
    "    # filter for same or up to n_weeks weeks before the cluster week\n",
    "    df_filtered = df_merged[\n",
    "        (df_merged['SURVEY_WEEK'] <= df_merged['CLUSTER_WEEK']) &\n",
    "        (df_merged['SURVEY_WEEK'] >= (df_merged['CLUSTER_WEEK'] - pd.Timedelta(weeks=n_weeks)))\n",
    "    ]\n",
    "\n",
    "    df_filtered = df_filtered.rename(columns={'CLUSTER_WEEK': 'WEEK_START'})\n",
    "    return df_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb63df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge survey and cluster subsets\n",
    "# now we have cluster_labels and all survey question answers in one frame for each category\n",
    "\n",
    "df_stress = filter_survey_weeks(df_survey_stress, df_clusters_stress, 3)\n",
    "df_stress = df_stress.sort_values(by=['USER_ID', 'SURVEY_WEEK'], ascending=[True, False])\n",
    "print(f\"Number of entries in stress: {len(df_stress)}\")\n",
    "\n",
    "df_depression = filter_survey_weeks(df_survey_depression, df_clusters_depression, 1)\n",
    "df_depression = df_depression.sort_values(by=['USER_ID', 'SURVEY_WEEK'], ascending=[True, False])\n",
    "print(f\"Number of entries in depression: {len(df_depression)}\")\n",
    "\n",
    "df_needs = filter_survey_weeks(df_survey_needs, df_clusters_needs, 0)\n",
    "df_needs = df_needs.sort_values(by=['USER_ID', 'SURVEY_WEEK'], ascending=[True, False])\n",
    "print(f\"Number of entries in needs: {len(df_needs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f0f9c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find total score of survey question of category\n",
    "\n",
    "def add_total_score(df):\n",
    "    # columns to exclude from the sum\n",
    "    non_questions = {\n",
    "        'USER_ID', 'WEEK_START', 'SURVEY_WEEK',\n",
    "        'UMAP_1', 'UMAP_2', 'cluster_label'\n",
    "    }\n",
    "    # every other column is assumed to be a survey question\n",
    "    question_cols = [c for c in df.columns if c not in non_questions]\n",
    "    # row-wise sum\n",
    "    df = df.copy()\n",
    "    df['total_score'] = df[question_cols].sum(axis=1)\n",
    "    return df\n",
    "\n",
    "df_stress = add_total_score(df_stress)\n",
    "df_depression = add_total_score(df_depression)\n",
    "df_needs = add_total_score(df_needs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b4fb3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to create table with mean and interquartile range of total score\n",
    "\n",
    "def make_summary_table(df, label, variable):\n",
    "    summary = df.groupby('cluster_label')[variable].agg(\n",
    "        median_score='median',\n",
    "        q1=lambda x: np.percentile(x, 25),\n",
    "        q3=lambda x: np.percentile(x, 75)\n",
    "    ).reset_index()\n",
    "\n",
    "    summary['Interquartile range'] = summary.apply(\n",
    "        lambda row: f\"{int(row['q1'])}–{int(row['q3'])}\", axis=1\n",
    "    )\n",
    "    summary['Median score'] = summary['median_score'].astype(int)\n",
    "\n",
    "    final = summary[['cluster_label', 'Median score', 'Interquartile range']]\n",
    "    final.columns = ['Cluster', f'Median {variable} Score', 'Interquartile range']\n",
    "\n",
    "    print(f\"--- {label.upper()} Summary Table ---\")\n",
    "    print(final.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb77839",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show summary tables\n",
    "\n",
    "make_summary_table(df_stress, \"Stress\", 'total_score')\n",
    "make_summary_table(df_depression, \"Depression\", 'total_score')\n",
    "make_summary_table(df_needs, \"Needs\", 'total_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d3c090",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create data frames of demographics and cluster labels of survey category\n",
    "df_demo_cluster_stress = df_demographics.merge(df_clusters_stress, on='USER_ID', how=\"inner\")\n",
    "df_demo_cluster_depression = df_demographics.merge(df_clusters_depression, on='USER_ID', how=\"inner\")\n",
    "df_demo_cluster_needs = df_demographics.merge(df_clusters_needs, on='USER_ID', how=\"inner\")\n",
    "\n",
    "# show summary tables of demographics\n",
    "make_summary_table(df_demo_cluster_stress, \"Stress\", 'AGE')\n",
    "make_summary_table(df_demo_cluster_depression, \"Depression\", 'AGE')\n",
    "make_summary_table(df_demo_cluster_needs, \"Needs\", 'AGE')\n",
    "\n",
    "make_summary_table(df_demo_cluster_stress, \"Stress\", 'BMI')\n",
    "make_summary_table(df_demo_cluster_depression, \"Depression\", 'BMI')\n",
    "make_summary_table(df_demo_cluster_needs, \"Needs\", 'BMI')\n",
    "\n",
    "# gender summary table\n",
    "gender_counts = df_demo_cluster_stress.groupby(['cluster_label', 'GENDER']).size().unstack(fill_value=0)\n",
    "gender_ratios = gender_counts.div(gender_counts.sum(axis=1), axis=0)\n",
    "print(\"==== Stress ====\")\n",
    "print(\"Gender ratios per cluster:\")\n",
    "print(gender_ratios.round(3))\n",
    "\n",
    "gender_counts = df_demo_cluster_depression.groupby(['cluster_label', 'GENDER']).size().unstack(fill_value=0)\n",
    "gender_ratios = gender_counts.div(gender_counts.sum(axis=1), axis=0)\n",
    "print(\"==== Depression ====\")\n",
    "print(\"Gender ratios per cluster:\")\n",
    "print(gender_ratios.round(3))\n",
    "\n",
    "gender_counts = df_demo_cluster_needs.groupby(['cluster_label', 'GENDER']).size().unstack(fill_value=0)\n",
    "gender_ratios = gender_counts.div(gender_counts.sum(axis=1), axis=0)\n",
    "print(\"==== Needs ====\")\n",
    "print(\"Gender ratios per cluster:\")\n",
    "print(gender_ratios.round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "041a06b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to check feature correlation with survey total scores and adjust for confounding variables\n",
    "\n",
    "def feature_correlation(df_category, df_features, df_demographics, category, confounders=('AGE', 'GENDER', 'BMI')):\n",
    "    \n",
    "    id_cols = ['USER_ID', 'WEEK_START']\n",
    "    df_category = df_category[id_cols + ['cluster_label', 'total_score']]\n",
    "    \n",
    "    # only keep confounders in df_demographics\n",
    "    df_demographics = df_demographics[['USER_ID'] + list(confounders)]\n",
    "    \n",
    "    # merge survey category and demographics\n",
    "    df_category = df_category.merge(df_demographics, on='USER_ID', how='left', validate='many_to_many')    \n",
    "    \n",
    "    # merge everything into one data frame\n",
    "    df = df_category.merge(df_features, on=id_cols, how='inner', validate='many_to_many')\n",
    "    \n",
    "    exclude_cols = set(id_cols + ['cluster_label', 'total_score'] + list(confounders))\n",
    "    feature_cols = [col for col in df.columns if col not in exclude_cols]\n",
    "    \n",
    "    clusters = sorted(df['cluster_label'].unique())\n",
    "    results = {}\n",
    "\n",
    "    for cluster in clusters:\n",
    "        df_cluster = df[df['cluster_label'] == cluster].dropna()\n",
    "        \n",
    "        # regress out confounding variables from total score and create residuals\n",
    "        formula_t = \"total_score ~ AGE + C(GENDER) + BMI\"\n",
    "        resid_t = smf.ols(formula_t, data=df_cluster).fit().resid\n",
    "        \n",
    "        corrs = []\n",
    "\n",
    "        for feature in feature_cols:\n",
    "            # regress out confounding variables from features and create residuals\n",
    "            formula_f = f\"{feature} ~ AGE + C(GENDER) + BMI\"\n",
    "            resid_f = smf.ols(formula_f, data=df_cluster).fit().resid\n",
    "            \n",
    "            try:\n",
    "                r, p = pearsonr(resid_t, resid_f)\n",
    "            except Exception:\n",
    "                r, p = np.nan, np.nan\n",
    "            \n",
    "            corrs.append({\n",
    "                'Variable': feature,\n",
    "                'r_adj': round(r, 4),\n",
    "                'p_adj': p\n",
    "            })\n",
    "\n",
    "        results[cluster] = pd.DataFrame(corrs)\n",
    "    \n",
    "    print(f\"=== {category} (adjusted) ===\")\n",
    "\n",
    "    for cluster_id, df_corr in results.items():\n",
    "        print(f\"--- Pearson Correlations for Cluster {cluster_id} ---\")\n",
    "        print(df_corr.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a71dc485",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load features for each category\n",
    "df_features_stress = pd.read_csv(f\"working_data/mhs_sleep_weekly_uncorr_features_correlation_threshold_{correlation_threshold}_{group}_stress.csv\")\n",
    "df_features_stress = df_features_stress.dropna()\n",
    "df_features_stress['WEEK_START'] = pd.to_datetime(df_features_stress['WEEK_START'])\n",
    "\n",
    "df_features_depression = pd.read_csv(f\"working_data/mhs_sleep_weekly_uncorr_features_correlation_threshold_{correlation_threshold}_{group}_depression.csv\")\n",
    "df_features_depression = df_features_depression.dropna()\n",
    "df_features_depression['WEEK_START'] = pd.to_datetime(df_features_depression['WEEK_START'])\n",
    "\n",
    "df_features_needs = pd.read_csv(f\"working_data/mhs_sleep_weekly_uncorr_features_correlation_threshold_{correlation_threshold}_{group}_needs.csv\")\n",
    "df_features_needs = df_features_needs.dropna()\n",
    "df_features_needs['WEEK_START'] = pd.to_datetime(df_features_needs['WEEK_START'])\n",
    "\n",
    "feature_correlation(df_stress, df_features_stress, df_demographics, \"Stress\")\n",
    "feature_correlation(df_depression, df_features_depression, df_demographics, \"Depression\")\n",
    "feature_correlation(df_needs, df_features_needs, df_demographics, \"Needs\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
